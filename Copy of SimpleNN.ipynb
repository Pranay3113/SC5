{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Copy of SimpleNN.ipynb","provenance":[{"file_id":"1j2H4c0CDoeJ4eWAvzRUfNgp3HoCL3KNc","timestamp":1569258241918}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"nYfpodeFmM9X","colab_type":"text"},"source":["# Simple NN, initialization, query & train"]},{"cell_type":"code","metadata":{"id":"qkQBqLimmM9Z","colab_type":"code","colab":{}},"source":["import numpy\n","#scipy.special for sigmoid function expit()\n","import scipy.special\n","\n","import matplotlib.pyplot\n","%matplotlib inline\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOFozggfD9nd","colab_type":"text"},"source":["Writing a function to create a neural network using sigmoid activation function"]},{"cell_type":"code","metadata":{"id":"kzv1KbpKmM9c","colab_type":"code","colab":{}},"source":["# neural network class definition\n","class neuralNetwork:\n","    \n","    \n","    # initialise the neural network\n","    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n","        # set number of nodes in each input, hidden, output layer\n","        self.inodes = inputnodes\n","        self.hnodes = hiddennodes\n","        self.onodes = outputnodes\n","\n","        # learning rate\n","        self.lr = learningrate\n","        \n","                \n","        # link weight matrices, wih and who\n","        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n","        # w11 w21\n","        # w12 w22 etc \n","        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n","        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n","        \n","        # activation function is the sigmoid function\n","        self.activation_function = lambda x: scipy.special.expit(x)\n","        \n","        pass\n","    \n","    # train the neural network\n","    def train(self, inputs_list, targets_list):\n","        # convert inputs list to 2d array\n","        inputs = numpy.array(inputs_list, ndmin=2).T\n","        targets = numpy.array(targets_list, ndmin=2).T\n","        \n","        # calculate signals into hidden layer\n","        hidden_inputs = numpy.dot(self.wih, inputs)\n","        # calculate the signals emerging from hidden layer\n","        hidden_outputs = self.activation_function(hidden_inputs)\n","        \n","        # calculate signals into final output layer\n","        final_inputs = numpy.dot(self.who, hidden_outputs)\n","        # calculate the signals emerging from final output layer\n","        final_outputs = self.activation_function(final_inputs)\n","        \n","        # output layer error is the (target - actual)\n","        output_errors = targets - final_outputs\n","        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n","        hidden_errors = numpy.dot(self.who.T, output_errors) \n","        \n","        # update the weights for the links between the hidden and output layers\n","        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n","        \n","        # update the weights for the links between the input and hidden layers\n","        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n","        \n","        pass\n","    \n","    # query the neural network\n","    def query(self, inputs_list):\n","        # convert inputs list to 2d array\n","        inputs = numpy.array(inputs_list, ndmin=2).T\n","             \n","        # calculate signals into hidden layer\n","        hidden_inputs = numpy.dot(self.wih, inputs)\n","        # calculate the signals emerging from hidden layer\n","        hidden_outputs = self.activation_function(hidden_inputs)\n","        \n","        # calculate signals into final output layer\n","        final_inputs = numpy.dot(self.who, hidden_outputs)\n","        # calculate the signals emerging from final output layer\n","        final_outputs = self.activation_function(final_inputs)\n","        \n","        return final_outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"esOdOwwImM9e","colab_type":"code","colab":{}},"source":["# number of input, hidden and output nodes\n","input_nodes = 3\n","hidden_nodes = 3\n","output_nodes = 3\n","\n","# learning rate is 0.3\n","learning_rate = 0.3\n","\n","# create instance of neural network\n","n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgMqWpQZmM9i","colab_type":"code","colab":{}},"source":["# link weight matrices, wih and who\n","# weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n","# w11 w21\n","# w12 w22 etc \n","\n","#wih = (numpy.random.rand(n.hnodes, n.inodes)-0.5)\n","#who = (numpy.random.rand(n.onodes, n.hnodes)-0.5)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSUwyv-rmM9k","colab_type":"code","colab":{},"outputId":"2f0355ec-1d7d-403f-b76d-d75d61fd394f"},"source":["print(n.wih)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[-0.6089006   0.47836402 -1.07105264]\n"," [-0.23738511  0.07391861 -1.05500814]\n"," [ 0.3097048   0.20003387  0.94501092]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u03_xLVwmM9o","colab_type":"code","colab":{},"outputId":"bbaaa864-1031-466c-a1e0-ac7d71e99da5"},"source":["print(n.who)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[-0.47498515  0.02971418  0.47568873]\n"," [ 0.91687815 -0.54792445 -0.74404692]\n"," [ 0.52497249 -0.75453811 -0.68996366]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wFcYmbG2mM9r","colab_type":"code","colab":{},"outputId":"2d49465d-ebe5-4486-b2f8-e9a20bf8ce7c"},"source":["# test query (doesn't mean anything useful yet)\n","n.query([.5, 0.4, -1.2])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.44957867],\n","       [0.51650513],\n","       [0.4072176 ]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"zJlRq7jYmM9t","colab_type":"code","colab":{}},"source":["# open the CSV file and read its contents into a list\n","data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n","data_list = data_file.readlines()\n","data_file.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSIaBM6_mM9w","colab_type":"code","colab":{},"outputId":"ba8585c9-3cee-46c5-84cf-1c152cbb6fb8"},"source":["# check the number of data records (examples)\n","len(data_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"uzMXTcNImM9z","colab_type":"code","colab":{},"outputId":"9649d3f1-ee70-4c72-f1dc-6e8b77df0929"},"source":["# show a dataset record\n","# the first number is the label, the rest are pixel colour values (greyscale 0-255)\n","data_list[1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,159,253,159,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,238,252,252,252,237,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,227,253,252,239,233,252,57,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,60,224,252,253,252,202,84,252,253,122,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,163,252,252,252,253,252,252,96,189,253,167,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,238,253,253,190,114,253,228,47,79,255,168,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,238,252,252,179,12,75,121,21,0,0,253,243,50,0,0,0,0,0,0,0,0,0,0,0,0,0,38,165,253,233,208,84,0,0,0,0,0,0,253,252,165,0,0,0,0,0,0,0,0,0,0,0,0,7,178,252,240,71,19,28,0,0,0,0,0,0,253,252,195,0,0,0,0,0,0,0,0,0,0,0,0,57,252,252,63,0,0,0,0,0,0,0,0,0,253,252,195,0,0,0,0,0,0,0,0,0,0,0,0,198,253,190,0,0,0,0,0,0,0,0,0,0,255,253,196,0,0,0,0,0,0,0,0,0,0,0,76,246,252,112,0,0,0,0,0,0,0,0,0,0,253,252,148,0,0,0,0,0,0,0,0,0,0,0,85,252,230,25,0,0,0,0,0,0,0,0,7,135,253,186,12,0,0,0,0,0,0,0,0,0,0,0,85,252,223,0,0,0,0,0,0,0,0,7,131,252,225,71,0,0,0,0,0,0,0,0,0,0,0,0,85,252,145,0,0,0,0,0,0,0,48,165,252,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,86,253,225,0,0,0,0,0,0,114,238,253,162,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,85,252,249,146,48,29,85,178,225,253,223,167,56,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,85,252,252,252,229,215,252,252,252,196,130,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,199,252,252,253,252,252,233,145,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,128,252,253,252,141,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"8wVPC3lkmM92","colab_type":"code","colab":{},"outputId":"d00350bd-54d9-40f2-9f5a-dfecb0ef1fe2"},"source":["# take the data from a record, rearrange it into a 28*28 array and plot it as an image\n","all_values = data_list[1].split(',')\n","print(all_values)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '51', '159', '253', '159', '50', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '48', '238', '252', '252', '252', '237', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '54', '227', '253', '252', '239', '233', '252', '57', '6', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '10', '60', '224', '252', '253', '252', '202', '84', '252', '253', '122', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '163', '252', '252', '252', '253', '252', '252', '96', '189', '253', '167', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '51', '238', '253', '253', '190', '114', '253', '228', '47', '79', '255', '168', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '48', '238', '252', '252', '179', '12', '75', '121', '21', '0', '0', '253', '243', '50', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '38', '165', '253', '233', '208', '84', '0', '0', '0', '0', '0', '0', '253', '252', '165', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '7', '178', '252', '240', '71', '19', '28', '0', '0', '0', '0', '0', '0', '253', '252', '195', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '57', '252', '252', '63', '0', '0', '0', '0', '0', '0', '0', '0', '0', '253', '252', '195', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '198', '253', '190', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '255', '253', '196', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '76', '246', '252', '112', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '253', '252', '148', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '85', '252', '230', '25', '0', '0', '0', '0', '0', '0', '0', '0', '7', '135', '253', '186', '12', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '85', '252', '223', '0', '0', '0', '0', '0', '0', '0', '0', '7', '131', '252', '225', '71', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '85', '252', '145', '0', '0', '0', '0', '0', '0', '0', '48', '165', '252', '173', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '86', '253', '225', '0', '0', '0', '0', '0', '0', '114', '238', '253', '162', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '85', '252', '249', '146', '48', '29', '85', '178', '225', '253', '223', '167', '56', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '85', '252', '252', '252', '229', '215', '252', '252', '252', '196', '130', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '28', '199', '252', '252', '253', '252', '252', '233', '145', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '25', '128', '252', '253', '252', '141', '37', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0\\n']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fXn0XGbQmM95","colab_type":"code","colab":{},"outputId":"935961c4-3d11-4f6b-8ade-c0a6bb741497"},"source":["image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n","matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x2881bed5898>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"K8qxuWnwmM97","colab_type":"code","colab":{},"outputId":"b11bbf2a-5afc-43a1-e017-2e874c65d51c"},"source":["# scale input to range 0.01 to 1.00\n","scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n","print(scaled_input)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.208      0.62729412 0.99223529 0.62729412 0.20411765\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.19635294 0.934\n"," 0.98835294 0.98835294 0.98835294 0.93011765 0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.21964706 0.89129412 0.99223529 0.98835294 0.93788235\n"," 0.91458824 0.98835294 0.23129412 0.03329412 0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.04882353 0.24294118 0.87964706\n"," 0.98835294 0.99223529 0.98835294 0.79423529 0.33611765 0.98835294\n"," 0.99223529 0.48364706 0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.64282353 0.98835294 0.98835294 0.98835294 0.99223529\n"," 0.98835294 0.98835294 0.38270588 0.74376471 0.99223529 0.65835294\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.208      0.934\n"," 0.99223529 0.99223529 0.74764706 0.45258824 0.99223529 0.89517647\n"," 0.19247059 0.31670588 1.         0.66223529 0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.19635294 0.934      0.98835294 0.98835294 0.70494118\n"," 0.05658824 0.30117647 0.47976471 0.09152941 0.01       0.01\n"," 0.99223529 0.95341176 0.20411765 0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.15752941 0.65058824\n"," 0.99223529 0.91458824 0.81752941 0.33611765 0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.99223529 0.98835294\n"," 0.65058824 0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.03717647 0.70105882 0.98835294 0.94176471 0.28564706\n"," 0.08376471 0.11870588 0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.99223529 0.98835294 0.76705882 0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.23129412\n"," 0.98835294 0.98835294 0.25458824 0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.99223529 0.98835294 0.76705882 0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.77870588 0.99223529 0.74764706\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       1.         0.99223529\n"," 0.77094118 0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.30505882 0.96505882 0.98835294 0.44482353 0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.99223529 0.98835294 0.58458824 0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.34       0.98835294\n"," 0.90294118 0.10705882 0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.03717647 0.53411765\n"," 0.99223529 0.73211765 0.05658824 0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.34       0.98835294 0.87576471 0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.03717647 0.51858824 0.98835294 0.88352941 0.28564706\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.34       0.98835294 0.57294118 0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.19635294 0.65058824\n"," 0.98835294 0.68164706 0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.34388235 0.99223529\n"," 0.88352941 0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.45258824 0.934      0.99223529 0.63894118 0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.34       0.98835294 0.97670588 0.57682353\n"," 0.19635294 0.12258824 0.34       0.70105882 0.88352941 0.99223529\n"," 0.87576471 0.65835294 0.22741176 0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.34       0.98835294 0.98835294 0.98835294 0.89905882 0.84470588\n"," 0.98835294 0.98835294 0.98835294 0.77094118 0.51470588 0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.11870588 0.78258824\n"," 0.98835294 0.98835294 0.99223529 0.98835294 0.98835294 0.91458824\n"," 0.57294118 0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.10705882 0.50694118 0.98835294\n"," 0.99223529 0.98835294 0.55741176 0.15364706 0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01       0.01       0.01\n"," 0.01       0.01       0.01       0.01      ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zBOsGd7KmM99","colab_type":"code","colab":{},"outputId":"81f71c43-ed2d-437a-eba5-b0dae19378e2"},"source":["#output nodes is 10 (example)\n","onodes = 10\n","targets = numpy.zeros(onodes) + 0.01\n","targets[int(all_values[0])] = 0.99\n","print(targets)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BOKInxw-mM-A","colab_type":"code","colab":{}},"source":["# number of input, hidden and output nodes\n","input_nodes = 784\n","hidden_nodes = 200\n","output_nodes = 10\n","\n","# learning rate\n","learning_rate = 0.1\n","\n","# create instance of neural network\n","n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n","n.train(scaled_input, targets)        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNDXmzVVmM-D","colab_type":"code","colab":{},"outputId":"2f8ec2e8-6492-4c05-aa83-e1df6ead3592"},"source":["n.query(scaled_input)\n","\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.6928778 ],\n","       [0.3045112 ],\n","       [0.28209686],\n","       [0.29500609],\n","       [0.36028186],\n","       [0.24680356],\n","       [0.28415861],\n","       [0.38931141],\n","       [0.33414944],\n","       [0.27224128]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"AAJVO_WjmM-F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}